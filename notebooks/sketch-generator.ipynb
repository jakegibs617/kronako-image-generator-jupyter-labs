{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722dfa2-434e-42cc-8b64-502c93d94577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85f83c-670e-4049-9ef9-e4328d0f8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from transformers import CLIPTokenizerFast, CLIPTokenizer, T5TokenizerFast\n",
    "from huggingface_hub import login\n",
    "from diffusers import FluxPipeline\n",
    "from diffusers import StableDiffusionPipeline  # Corrected import\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from huggingface_hub import snapshot_download\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import re\n",
    "int_slider = widgets.IntSlider()\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"Torchaudio Version:\", torchaudio.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"MPS Available:\", torch.backends.mps.is_available())  # For Apple Silicon GPU support\n",
    "x = torch.rand(3, 3)\n",
    "print(\"Tensor:\", x)\n",
    "\n",
    "huggingface_token = os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "\n",
    "if huggingface_token is None:\n",
    "    raise ValueError(\"HUGGINGFACE_HUB_TOKEN environment variable is not set.\")\n",
    "\n",
    "# Authenticate with Hugging Face Hub\n",
    "login(token=huggingface_token)\n",
    "\n",
    "# ============================\n",
    "# Determine the Device and Set torch_dtype Accordingly\n",
    "# ============================\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    torch_dtype = torch.float16  # Optimal for MPS\n",
    "    print(\"Using MPS for acceleration.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    torch_dtype = torch.float32\n",
    "    print(\"Using CPU for computation.\")\n",
    "\n",
    "images_dir = os.path.join(os.getcwd(), \"../images\")\n",
    "# Create the images directory if it doesn't exist\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "print(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecaab2-fc60-4523-87fd-ffdfeca237ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Define Model Repository and Local Cache Directory\n",
    "# ============================\n",
    "models_dir = os.path.join(os.getcwd(), \"../models\")\n",
    "print(models_dir)  # Should output: /Users/username/Desktop/AI-projects/kronako-text2img/notebooks/../images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0c527-c213-4dc1-880e-a40122ebfcca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_repo = \"runwayml/stable-diffusion-v1-5\"  \n",
    "model_identifier_file = os.path.join(models_dir, \"stable-diffusion-v1-5.ckpt\") \n",
    "\n",
    "# ============================\n",
    "# Check if the Model is Already Downloaded\n",
    "# ============================\n",
    "if not os.path.exists(model_identifier_file):\n",
    "    model_local_path = snapshot_download(\n",
    "        repo_id=model_repo,\n",
    "        cache_dir=models_dir,\n",
    "        local_dir=models_dir,\n",
    "        local_dir_use_symlinks=False,  # Avoid using symlinks for better compatibility\n",
    "    )\n",
    "    print(f\"Model downloaded to: {model_local_path}\")\n",
    "else:\n",
    "    print(f\"Model already exists. Skipping download.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c055b-8e53-426e-9734-9efd74a1c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Load the Stable Diffusion Model\n",
    "# ============================\n",
    "try:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_repo,  # Use the model repository directly\n",
    "        torch_dtype=torch_dtype,\n",
    "        use_auth_token=huggingface_token  # Ensure authentication\n",
    "    )\n",
    "    \n",
    "    # Move the pipeline to the CPU\n",
    "    pipe = pipe.to(device)\n",
    "    \n",
    "    print(\"Stable Diffusion v1-5 pipeline loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the model: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d242a4d-4b4d-41a3-9fac-cb1cc3aa9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_prompt(prompt):\n",
    "    \"\"\"\n",
    "    Simplifies the prompt string to create a safe filename.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The original text prompt.\n",
    "    \n",
    "    Returns:\n",
    "        str: A simplified version of the prompt suitable for filenames.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    simplified = prompt.lower()\n",
    "    \n",
    "    # Remove non-alphanumeric characters (except spaces)\n",
    "    simplified = re.sub(r'[^a-z0-9\\s]', '', simplified)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    simplified = re.sub(r'\\s+', ' ', simplified)\n",
    "    \n",
    "    # Replace spaces with underscores\n",
    "    simplified = simplified.replace(' ', '_')\n",
    "    \n",
    "    return simplified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f56a8b-fc73-4572-95af-7b29102197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    \"\"\"\n",
    "    Generates a current timestamp.\n",
    "    \n",
    "    Returns:\n",
    "        str: Timestamp in 'YYYYMMDD_HHMMSS' format.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c685df-9118-4d87-a1df-981bae7ba11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filename(prompt, extension=\".png\", max_length=50, directory=images_dir):\n",
    "    \"\"\"\n",
    "    Creates a dynamic filename based on the prompt and current timestamp.\n",
    "    Ensures the filename is unique by checking existing files.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The original text prompt.\n",
    "        extension (str): File extension (default is '.png').\n",
    "        max_length (int): Maximum length for the simplified prompt part of the filename.\n",
    "        directory (str): Directory where the image will be saved.\n",
    "    \n",
    "    Returns:\n",
    "        str: A dynamic and unique filename with directory path.\n",
    "    \"\"\"\n",
    "    simplified_prompt = simplify_prompt(prompt)\n",
    "    \n",
    "    # Truncate if necessary to prevent overly long filenames\n",
    "    if len(simplified_prompt) > max_length:\n",
    "        simplified_prompt = simplified_prompt[:max_length]\n",
    "    \n",
    "    timestamp = get_timestamp()\n",
    "    filename = f\"{simplified_prompt}_{timestamp}{extension}\"\n",
    "    \n",
    "    # Combine directory and filename\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    # Ensure filename is unique\n",
    "    while os.path.exists(filepath):\n",
    "        timestamp = get_timestamp()\n",
    "        filename = f\"{simplified_prompt}_{timestamp}{extension}\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dce1c9-ece5-46c0-8918-44a6809c8445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_sketch(prompt, num_inference_steps=15, guidance_scale=7.5, height=512, width=512):\n",
    "    \"\"\"\n",
    "    Generates a sketch based on the provided text prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt describing the desired sketch.\n",
    "        num_inference_steps (int): Number of inference steps (trade-off between speed and quality).\n",
    "        guidance_scale (float): Controls how much the model follows the prompt (higher = more adherence).\n",
    "        height (int): Image height in pixels.\n",
    "        width (int): Image width in pixels.\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image: Generated sketch image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate the image\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            height=height,\n",
    "            width=width,\n",
    "        )\n",
    "        \n",
    "        # Retrieve the image\n",
    "        image = result.images[0]\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image generation: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ab382-c8b2-4545-b26b-081da9e37bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Define a Function to Generate and Save Sketches\n",
    "# ============================\n",
    "\n",
    "def generate_and_save_sketch(prompt, num_inference_steps=15, guidance_scale=7.5, height=512, width=512):\n",
    "    \"\"\"\n",
    "    Generates a sketch based on the provided text prompt and saves it with a dynamic filename.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt describing the desired sketch.\n",
    "        num_inference_steps (int): Number of inference steps.\n",
    "        guidance_scale (float): Controls how much the model follows the prompt.\n",
    "        height (int): Image height in pixels.\n",
    "        width (int): Image width in pixels.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Generate the sketch\n",
    "    print(\"Generating sketch...\")\n",
    "    sketch_image = generate_sketch(prompt, num_inference_steps=num_inference_steps, height=height, width=width)\n",
    "    \n",
    "    if sketch_image:\n",
    "        # Display the image\n",
    "        sketch_image.show()\n",
    "        \n",
    "        # Create a dynamic filename\n",
    "        output_path = create_filename(prompt)\n",
    "        \n",
    "        # Save the image locally\n",
    "        sketch_image.save(output_path)\n",
    "        print(f\"Sketch generated and saved successfully at {output_path}.\")\n",
    "    else:\n",
    "        print(\"Failed to generate the sketch.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970eaf47-ab11-4e10-9881-0127b155d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Bridging Shadows A bridge spanning a river, with shadowy figures on one side and brightly lit figures on the other. The water below reflects both sides, blending them into one indistinguishable image. Themes: Race and identity, unity and division, self-reflection. Why Lowell?: The city’s many bridges symbolize connection yet often divide communities by race and class.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a70932-a9f6-45f7-9c7b-2267d3dbd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_sketch(prompt, num_inference_steps=15, height=512, width=512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
